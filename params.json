{
  "name": "SparkR notebooks",
  "tagline": " R on Spark (SparkR) tutorials for Big Data analysis and Machine Learning as IPython / Jupyter notebooks",
  "body": "# SparkR Notebooks  \r\n\r\n[![Join the chat at https://gitter.im/jadianes/spark-r-notebooks](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/jadianes/spark-r-notebooks?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\r\n[![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=EJ54869W5H3KJ)   \r\n\r\nThis is a collection of [Jupyter](https://jupyter.org/) \r\nnotebooks intended to train the reader on different [Apache Spark](http://spark.apache.org/) concepts, from \r\nbasic to advanced, by using the **R** language.  \r\n\r\nIf your are interested in being introduced to some basic Data Science Engineering concepts and applications, you might find [these series of tutorials](https://github.com/jadianes/data-science-your-way) interesting. There we explain different concepts and applications \r\nusing Python and R. Additionally, if you are interested in using Python with Spark, you can have a look at our [pySpark notebooks]().    \r\n\r\n## Instructions  \r\n\r\nFor these series of notebooks, we have used [Jupyter](https://jupyter.org/) with the [IRkernel](http://irkernel.github.io/) R kernel. You can find installation instructions for you specific setup [here](http://irkernel.github.io/installation/). Have also a look at [Andrie de Vries](https://twitter.com/RevoAndrie) post [Using R with Jupyter Notebooks](http://blog.revolutionanalytics.com/2015/09/using-r-with-jupyter-notebooks.html) that includes instructions for installing Jupyter and IRkernel together.   \r\n\r\nA good way of using these notebooks is by first cloning the repo, and then \r\nstarting your [Jupyter](https://jupyter.org/) in **pySpark mode**. For example, \r\nif we have a *standalone* Spark installation running in our `localhost` with a \r\nmaximum of 6Gb per node assigned to IPython:  \r\n\r\n    MASTER=\"spark://127.0.0.1:7077\" SPARK_EXECUTOR_MEMORY=\"6G\" IPYTHON_OPTS=\"notebook --pylab inline\" ~/spark-1.5.0-bin-hadoop2.6/bin/pyspark\r\n\r\nNotice that the path to the `pyspark` command will depend on your specific \r\ninstallation. So as requirement, you need to have\r\n[Spark installed](https://spark.apache.org/docs/latest/index.html) in \r\nthe same machine you are going to start the `IPython notebook` server.     \r\n\r\nFor more Spark options see [here](https://spark.apache.org/docs/latest/spark-standalone.html). In general it works the rule of passign options \r\ndescribed in the form `spark.executor.memory` as `SPARK_EXECUTOR_MEMORY` when\r\ncalling IPython/pySpark.   \r\n\r\n\r\n## Datasets  \r\n\r\n#### [2013 American Community Survey dataset](http://www.census.gov/programs-surveys/acs/data/summary-file.html).  \r\n\r\nEvery year, the US Census Bureau runs the American Community Survey. In this survey, approximately 3.5 million \r\nhouseholds are asked detailed questions about who they are and how they live. Many topics are covered, including \r\nancestry, education, work, transportation, internet use, and residency. You can directly to \r\n[the source](http://www.census.gov/programs-surveys/acs/data/summary-file.html) \r\nin order to know more about the data and get files for different years, longer periods, individual states, etc. \r\n\r\nIn any case, the [starting up notebook](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb0-starting-up/nb0-starting-up.ipynb) \r\nwill download the 2013 data locally for later use with the rest of the notebooks. \r\n\r\nThe idea of using this dataset came from being recently [announced in Kaggle](https://www.kaggle.com/c/2013-american-community-survey)\r\n as part of their Kaggle scripts datasets. There you will be able to analyse the dataset on site, while sharing your results with other Kaggle\r\nusers. Highly recommended!  \r\n\r\n## Notebooks  \r\n\r\n#### [Downloading data and starting with SparkR](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb0-starting-up/nb0-starting-up.ipynb)  \r\n\r\nWhere we download our data locally and start up a SparkR cluster.  \r\n\r\n#### [SparkSQL basics with SparkR](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb1-spark-sql-basics/nb1-spark-sql-basics.ipynb)  \r\n\r\nAbout loading our data into SparkSQL data frames using SparkR.  \r\n\r\n#### [Data frame operations with SparkSQL and SparkR](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb2-spark-sql-operations/nb2-spark-sql-operations.ipynb)  \r\n\r\nDifferent operations we can use with SparkR and `DataFrame` objects, such as data selection and filtering, aggregations, and sorting. The basis for exploratory data analysis and machine learning.  \r\n\r\n#### [Exploratory Data Analysis with SparkR and ggplot2](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb3-eda/nb3-eda.ipynb)  \r\n\r\nHow to explore different types of variables using SparkR and ggplot2 charts.  \r\n\r\n\r\n#### [Linear Models with SparkR](https://github.com/jadianes/spark-r-notebooks/blob/master/notebooks/nb4-linear-models/nb4-linear-models.ipynb)  \r\n\r\nAbout linear models using SparkR, its uses and current limitations in v1.5.  \r\n\r\n## Applications  \r\n\r\n#### [Exploring geographical data with SparkR and ggplot2](https://github.com/jadianes/spark-r-notebooks/blob/master/applications/exploring-maps/exploring-maps.ipynb)  \r\n\r\nAn Exploratory Data Analysis of the [2013 American Community Survey](http://www.census.gov/programs-surveys/acs/data/summary-file.html) dataset, more concretely its geographical features.  \r\n\r\n## Contributing\r\n\r\nContributions are welcome!  For bug reports or requests please [submit an issue](https://github.com/jadianes/spark-r-notebooks/issues).\r\n\r\n## Contact  \r\n\r\nFeel free to contact me to discuss any issues, questions, or comments.\r\n\r\n* Twitter: [@ja_dianes](https://twitter.com/ja_dianes)\r\n* GitHub: [jadianes](https://github.com/jadianes)\r\n* LinkedIn: [jadianes](https://www.linkedin.com/in/jadianes)\r\n* Website: [jadianes.me](http://jadianes.me)\r\n\r\n## License\r\n\r\nThis repository contains a variety of content; some developed by Jose A. Dianes, and some from third-parties.  The third-party content is distributed under the license provided by those parties.\r\n\r\nThe content developed by Jose A. Dianes is distributed under the following license:\r\n\r\n    Copyright 2016 Jose A Dianes\r\n\r\n    Licensed under the Apache License, Version 2.0 (the \"License\");\r\n    you may not use this file except in compliance with the License.\r\n    You may obtain a copy of the License at\r\n\r\n       http://www.apache.org/licenses/LICENSE-2.0\r\n\r\n    Unless required by applicable law or agreed to in writing, software\r\n    distributed under the License is distributed on an \"AS IS\" BASIS,\r\n    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n    See the License for the specific language governing permissions and\r\n    limitations under the License.\r\n\r\n## Donate  \r\n\r\nIf you find these tutorials useful then you can help me to keep them updated ;)  \r\n\r\n[![Donate](https://img.shields.io/badge/Donate-PayPal-green.svg)](https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=EJ54869W5H3KJ)  \r\n\r\n",
  "google": "",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}